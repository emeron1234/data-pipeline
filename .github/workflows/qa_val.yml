name: QA Validation Job

on:
  workflow_call:
    inputs:
      environment:
        type: string
        required: true
        description: Deployment environment
      space:
        type: string
        required: true
        description: Space
      object_type:
        type: string
        required: true
        description: Object Type
      job_type:
        type: string
        required: true
        description: Job type
      test_type:
        type: string
        required: true
        description: Test type
      deploy:
        type: boolean
        required: true
        description: Deploy a workflow before launching it
      skip_test:
        type: boolean
        description: Skip test
      deployment_file:
        type: string
        required: true
        description: File deployment
    secrets:
      DATABRICKS_HOST:
        required: true
      DATABRICKS_TOKEN:
        required: true
      GH_TOKEN:
        required: true

jobs:
  qa-deploy-config:
    environment: ${{ inputs.environment }}_${{ inputs.space }}
    runs-on: ubuntu-latest
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      GH_TOKEN: ${{ secrets.GH_TOKEN }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel
          pip install -e ".[dev]"
      # # Testing ----------------------------
      # # Check DATABRICKS_HOST
      # - name: Check DATABRICKS_HOST host resolves
      #   run: |
      #     if [[ ! "$DATABRICKS_HOST" =~ ^https?:// ]]; then
      #       echo "Error: DATABRICKS_HOST must start with http:// or https://"
      #       exit 1
      #     fi
      #     curl -Is --fail "$DATABRICKS_HOST" || { echo "âŒ Host not reachable"; exit 1; }
      #     echo "âœ… Host is reachable"
      
      # # Check DATABRICKS_TOKEN
      # - name: Check DATABRICKS_TOKEN authentication
      #   run: |
      #     response=$(curl -s -o /dev/null -w "%{http_code}" \
      #       -H "Authorization: Bearer $DATABRICKS_TOKEN" \
      #       "$DATABRICKS_HOST/api/2.0/clusters/list")

      #     if [ "$response" -eq 200 ]; then
      #       echo "âœ… DATABRICKS_TOKEN is valid."
      #     elif [ "$response" -eq 401 ]; then
      #       echo "âŒ Unauthorized: DATABRICKS_TOKEN is invalid or expired."
      #       exit 1
      #     else
      #       echo "âš ï¸ Unexpected response code: $response"
      #       exit 1
      #     fi

      # # Check GH_TOKEN
      # - name: Check GH_TOKEN authentication
      #   run: |
      #     user=$(curl -s -H "Authorization: token $GH_TOKEN" https://api.github.com/user | jq -r '.login')
      #     if [ "$user" = "null" ] || [ -z "$user" ]; then
      #       echo "âŒ GH_TOKEN invalid or expired."
      #       exit 1
      #     else
      #       echo "âœ… Authenticated as: $user"
      #     fi
      # # Check GH_TOKEN User
      # - name: Check GitHub user
      #   run: |
      #     curl -s -H "Authorization: token $GH_TOKEN" https://api.github.com/user | jq
      
      # - name: Check if secrets are available
      #   run: |
      #     if [ -z "${{ secrets.GH_TOKEN }}" ]; then
      #       echo "Secrets not set properly. ${{ secrets.GH_TOKEN }} "
      #       exit 1
      #     else
      #       echo "Secrets are set"
      #     fi
      # # Testing ----------------------------
      # - name: Upload config file to Unity Catalog Volume (overwrite-safe)
      #   run: |
      #     set -e
      #     file_path="/Volumes/data_lake_dev/feature_config/volume/data_pipeline_config_dev.json"

      #     echo "ðŸ§¹ Deleting existing file if present..."
      #     curl -s -X DELETE -H "Authorization: Bearer $DATABRICKS_TOKEN" \
      #       "$DATABRICKS_HOST/api/2.1/unity-catalog/volumes/files/delete?path=${file_path}" || true

      #     echo "â¬†ï¸ Uploading configuration file..."
      #     status=$(curl -s -o /dev/null -w "%{http_code}" \
      #       -X POST -H "Authorization: Bearer $DATABRICKS_TOKEN" \
      #       -F path="${file_path}" \
      #       -F contents=@data_pipeline/core/config/data_pipeline_config_dev.json \
      #       "$DATABRICKS_HOST/api/2.1/unity-catalog/volumes/files/upload")

      #     if [ "$status" -eq 200 ]; then
      #       echo "âœ… File uploaded successfully to ${file_path}"
      #     else
      #       echo "âŒ Upload failed with status code: $status"
      #       exit 1
      #     fi

      #   # databricks fs cp --overwrite data_pipeline/core/config/data_pipeline_config_dev.json /Volumes/data_lake_dev/feature_config/volume/data_pipeline_config_dev.json


      - name: Install latest dbx
        run: |
          pip install --upgrade pip
          pip install "dbx>=0.8.19" --no-cache-dir



      - name: Deploy Integration Test Suite
        run: |
          dbx deploy --job=we-pipeline-${{ inputs.job_type }}-${{ inputs.test_type }}-${{ inputs.environment }}-${{ inputs.space }}-val-v1 --deployment-file=${{ inputs.deployment_file }} --environment ${{ inputs.environment }}_${{ inputs.space }} --debug
      - name: Run Integration test suite for cross_platform_count
        run: |
            dbx launch --job=we-pipeline-${{ inputs.job_type }}-${{ inputs.test_type }}-${{ inputs.environment }}-${{ inputs.space }}-val-v1 --trace --environment ${{ inputs.environment }}_${{ inputs.space }} --parameters='{"python_params": ["we.pipeline.validation.task.${{ inputs.job_type }}_val", "--env", "'${{ inputs.environment }}'", "--space", "'${{ inputs.space }}'", "--object_type", "'${{ inputs.object_type }}'", "--job_type", "'${{ inputs.job_type }}'", "--test_type", "'${{ inputs.test_type }}'"]}'