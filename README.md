# Data Pipeline - Databricks Asset Bundle (DAB) Project

The project demonstrates end-to-end expertise in ETL pipeline development, data quality validation and CI/CD automation which, deployed using **Databricks Asset Bundles (DAB)** for modern CI/CD practices.

### **Business Requirement** ###
Engineered a scalable data pipeline processing **Contact Information** and **Real Estate** datasets through a multi-layer architecture, ensuring data quality, compliance, and production readiness for enterprise analytics.

---

## ğŸš€ Quick Start

### **Project Highlights**
- Pipeline Architecture implementation
    - Bronze â†’ Silver â†’ Gold
- Automated CI/CD pipeline
    - using GithHub Action
- QA Framework
    - Smoke and Regression testing
- Modern Deployment
    - using Databricks Asset Bundles (DAB)
- Data Quality validation
    - performed at every stage of task run

### **CI/CD Deployment**
The GitHub Actions workflow automatically:
1. âœ… Installs correct Databricks CLI
2. âœ… Validates bundle configuration
3. âœ… Deploys to Databricks workspace
4. âœ… Runs validation jobs

---

## ğŸ“‹ Project Structure

```
data-pipeline/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ qa_val.yml              # CI/CD workflow (DAB-based)
â”œâ”€â”€ data_pipeline/              # Application code
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ real_estate/
â”‚   â””â”€â”€ validation/
â”œâ”€â”€ databricks.yml              # DAB configuration (MAIN)
â””â”€â”€ setup.py                    # Python package setup
```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA ENGINEERING PIPELINE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
ğŸ“ Data Sources                  ğŸ”„ Processing Layers              ğŸ“Š Analytics
     â”‚                                   â”‚                             â”‚
     â”œâ”€â–º Synthetic Data â”€â”€â”€â”€â”€â”€â”€â”€â–º ğŸŸ¦ Raw Zone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
     â”‚   Generator                  â”‚ (Parquet Files)                 â”‚
     â”‚   (Faker)                    â”‚ - No transformation             â”‚
     â”‚                              â”‚ - Batch tracking                â”‚
     â”‚                              â”‚                                 â”‚
     â”‚                              â–¼                                 â”‚
     â”‚                         ğŸŸ§ Bronze Zone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
     â”‚                              â”‚ - Data cleansing                â”‚
     â”‚                              â”‚ - Null filtering                â”‚
     â”‚                              â”‚ - Special char removal          â”‚
     â”‚                              â”‚ - Phone standardization         â”‚
     â”‚                              â”‚ - Name normalization            â”‚
     â”‚                              â”‚                                 â”‚
     â”‚                              â–¼                                 â”‚
     â”‚                         ğŸŸ¨ Silver Zone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
     â”‚                              â”‚ - Delta Lake tables             â”‚
     â”‚                              â”‚ - Schema evolution              â”‚
     â”‚                              â”‚ - ACID transactions             â”‚
     â”‚                              â”‚ - Ready for analytics           â”‚
     â”‚                              â”‚                                 â”‚
     â”‚                              â–¼                                 â”‚
     â”‚                         ğŸŸ© Gold Zone (Planned) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
     â”‚                                - Aggregations                  â”‚
     â”‚                                - Business metrics              â”‚
     â”‚                                - Feature engineering           â”‚
     â”‚                                                                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
                    âœ… Validation Layer (Parallel)
                         â”‚
                         â”œâ”€â–º Smoke Tests (Fast)
                         â”‚   - Schema validation
                         â”‚   - Row count checks
                         â”‚   - Critical column checks
                         â”‚
                         â””â”€â–º Regression Tests (Comprehensive)
                             - Data comparison
                             - Business rule validation
                             - Historical consistency

---

## ğŸ”§ Key Technologies

- **Deployment**: Databricks Asset Bundles (DAB)
- **CI/CD**: GitHub Actions
- **Language**: Python 3.9+
- **Build**: setuptools (wheel packages)
- **Orchestration**: Databricks Workflows

---
