## Serverless-compatible job deployment for validation (dev_feature)
# This file is tailored for workspaces that only allow Serverless (no classic clusters).
# Key points:
# - Uses job_clusters with a serverless single-node spec (num_workers: 0)
# - Adds spark.databricks.cluster.profile=serverless and node_type_id=serverless
# - Includes PHOTON runtime_engine for better performance (optional)
# - Keeps parameters consistent with existing validation tasks

environments:
  dev_feature:
    workflows:
      - name: "we-pipeline-rep-smoke-dev-feature-val-v1"
        job_clusters: []

        tasks:
          - task_key: "rep_dev_feature_validation_task"
            job_cluster_key: null  # not needed
            existing_cluster_id: null  # not needed
            serverless: true   # ðŸ‘ˆ NEW FIELD for Databricks Premium/Serverless

            spark_python_task:
              python_file: "file://main.py"
              parameters: [ "data_pipeline.validation.task.rep_val", "--env", "dev", "--space", "feature", "--zone", "raw", "--object_type", "re", "--job_type", "rep", "--test_type", "smoke" ]

        # compute:
        #   - compute_key: serverless_compute
        #     compute_type: SERVERLESS
        #     spec:
        #       kind: SERVERLESS
        #       serverless:
        #         enabled: true


