## Serverless-compatible job deployment for validation (dev_feature)
# This file is tailored for workspaces that only allow Serverless (no classic clusters).
# Key points:
# - Uses job_clusters with a serverless single-node spec (num_workers: 0)
# - Adds spark.databricks.cluster.profile=serverless and node_type_id=serverless
# - Includes PHOTON runtime_engine for better performance (optional)
# - Keeps parameters consistent with existing validation tasks

environments:
  dev_feature:
    workflows:
      - name: "we-pipeline-rep-smoke-dev-feature-val-v1"
        job_clusters:
          - job_cluster_key: serverless_single_node
            new_cluster:
              compute_type: serverless
              spark_version: 13.3.x-scala2.12
              data_security_mode: SINGLE_USER
              custom_tags:
                ResourceClass: Serverless


        tasks:
          - task_key: "rep_dev_feature_validation_task"
            job_cluster_key: serverless_single_node
            spark_python_task:
              python_file: "file://main.py"
              parameters: [ "data_pipeline.validation.task.rep_val", "--env", "dev", "--space", "feature", "--zone", "raw", "--object_type", "re", "--job_type", "rep", "--test_type", "smoke" ]
              libraries:
              - whl: "dist/data_pipeline-1.0.0-py3-none-any.whl"
