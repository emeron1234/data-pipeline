## Serverless-compatible job deployment for validation (dev_feature)
# This file is tailored for workspaces that only allow Serverless (no classic clusters).
# Key points:
# - Uses job_clusters with a serverless single-node spec (num_workers: 0)
# - Adds spark.databricks.cluster.profile=serverless and node_type_id=serverless
# - Includes PHOTON runtime_engine for better performance (optional)
# - Keeps parameters consistent with existing validation tasks

environments:
  dev_feature:
    workflows:
      - name: "we-pipeline-rep-smoke-dev-feature-val-v1"
        job_clusters:
          - job_cluster_key: "single_node_cluster"
            new_cluster:
              spark_version: "14.3.x-scala2.12"
              node_type_id: "i3.xlarge"
              num_workers: 0
              spark_conf:
                spark.databricks.cluster.profile: "singleNode"
                spark.master: "local[*]"
              custom_tags:
                ResourceClass: "SingleNode"
              runtime_engine: "STANDARD"


        tasks:
          - task_key: "rep_dev_feature_validation_task"
            job_cluster_key: "single_node_cluster"
            spark_python_task:
              python_file: "file://main.py"
              parameters: [ "data_pipeline.validation.task.rep_val", "--env", "dev", "--space", "feature", "--zone", "raw", "--object_type", "re", "--job_type", "rep", "--test_type", "smoke" ]
              libraries:
              - whl: "dist/data_pipeline-1.0.0-py3-none-any.whl"

        # compute:
        #   - compute_key: serverless_compute
        #     compute_type: SERVERLESS
        #     spec:
        #       kind: SERVERLESS
        #       serverless:
        #         enabled: true


